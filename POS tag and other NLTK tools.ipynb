{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## libraries\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.spatial.distance\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## data loading\n",
    "qa = np.genfromtxt(\"uid_qa.txt\", delimiter = \",\", names = True, dtype = [('int64'), ('int64'), ('int64'), ('U256'), ('U128'),])\n",
    "fe = np.genfromtxt(\"uid_pre_elim.txt\", delimiter = \",\", names = True, dtype = [('int64'), ('int64'), ('int64'), ('U256'), ('U256'),])\n",
    "ftd = np.genfromtxt(\"face_id_descr.txt\", delimiter = \";\", skip_header = 1 , usecols = np.arange(0,2), dtype = [('U16'), ('U2056')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ftd.dtype.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#changing or adding names for the dtypes\n",
    "fe.dtype.names = ('uniqueID', 'bn', 'qn', 'pre_que', 'curr_elim')\n",
    "ftd.dtype.names = ('img_id', 'description')\n",
    "len(ftd['img_id'])\n",
    "len(set(ftd['img_id']))\n",
    "\n",
    "#fe.dtype.names\n",
    "#fe[971]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## first convert strings to list of rows equal to rows in fe\n",
    "def mk_list(str_vector):\n",
    "    des_byid = str_vector\n",
    "    all_x = []\n",
    "    for i in des_byid:\n",
    "        j = i.split()\n",
    "        #if len(j) > 0:\n",
    "        all_x.append(j)\n",
    "\n",
    "    return all_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_x = mk_list(fe['pre_que'])\n",
    "len(all_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Now for each row in the list above, find description and add it\n",
    "all_i_txt = []\n",
    "\n",
    "for rown in range(len(all_x)):\n",
    "    #if rown not in bl:\n",
    "        #print(all_x.index)\n",
    "    int_i_txt = []\n",
    "    for img in all_x[rown]:\n",
    "        if img in ftd['img_id']:\n",
    "            d = str(ftd['description'][list(ftd['img_id']).index(img)])\n",
    "            int_i_txt.append(str(d))\n",
    "    all_i_txt.append(int_i_txt)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## For each question, find the synonyms for all the adjectives, NN, NNS and CD. Then add that list of synonyms in the \n",
    "##column called question \n",
    "\n",
    "new_table_fd = [] ## for frequency distribution\n",
    "new_que_syn = []\n",
    "for rown in qa['que'] :\n",
    "    #print(rown[-2])\n",
    "    #new_row = []\n",
    "    sents = nltk.sent_tokenize(rown.strip())\n",
    "    \n",
    "    lw = [nltk.word_tokenize(s) for s in sents]\n",
    "    #p =[nltk.pos_tag(w) for w in lw]\n",
    "    x = [kv[0] for w in lw for kv in nltk.pos_tag(w) if kv[1] in ['JJ', 'NN', 'NNS', 'CD']]\n",
    "    fd = [kv[1] for w in lw for kv in nltk.pos_tag(w)]\n",
    "    #y = [wordnet.synsets(words) for words in x]\n",
    "    syn = [j.name() for words in x for i in wordnet.synsets(words) for j in i.lemmas()]\n",
    "    new_que_syn.append(list(set(syn)))\n",
    "    new_table_fd.extend([kv[0] for w in lw for kv in nltk.pos_tag(w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## add question and answer to each data point also convert the list of synonyms in the question to a string\n",
    "for it in range(len(all_i_txt)):\n",
    "    all_i_txt[it].extend([' '.join(map(str, new_que_syn[it])), qa['ans'][it].strip()])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## check addition of above objects\n",
    "for i in range(len(all_i_txt[0:2])):\n",
    "    print(all_i_txt[i][-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i in set(bl):\n",
    "#    print(all_i_txt[i][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for rown,qs in zip(all_i_txt[0:2],new_que_syn[0:2]):\n",
    "#    rown[-2] = qs\n",
    "#    print(rown[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fd1 = nltk.FreqDist(new_table_fd[0:20])\n",
    "fd1 = nltk.FreqDist(new_table_fd)\n",
    "fd1.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(all_i_txt[0])\n",
    "##basic model\n",
    "tf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sim_tf = []\n",
    "for l in range(len(all_i_txt)):\n",
    "    H = tf.fit_transform(all_i_txt[l])\n",
    "    sim = cosine_similarity(H)\n",
    "    all_sim_tf.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#similarities[-2] meaning taking only the array for question\n",
    "all_sim_q_tf = []\n",
    "for i in range(len(all_sim_tf)):\n",
    "    all_sim_q_tf.append(all_sim_tf[i][-2][:-2])\n",
    "print(len(all_sim_q_tf))\n",
    "#print(all_sim_q[971])\n",
    "#print(len(all_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cheat = mk_list(fe['curr_elim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cheat_code = zip(all_sim_q_tf, all_cheat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Sort all the above similarities with argsort which gives indices\n",
    "## or we should not take top5 and make a threshold above which we will include it in the list of output?\n",
    "sorted_ind = []\n",
    "for si, ln in cheat_code:\n",
    "    y_top = si.argsort()[::-1][:len(ln)]\n",
    "    sorted_ind.append(y_top)\n",
    "#sorted_ind[971]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_img = zip(all_x, sorted_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert to img_id from index to match with actual image ids selcted by participant\n",
    "def mk_imgid(arr):\n",
    "    y_pred = []\n",
    "    for i,j in arr:\n",
    "        yp = []\n",
    "        for s in j:\n",
    "            yp.append(i[s])\n",
    "        y_pred.append(yp)\n",
    "    return y_pred\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_img = mk_imgid(top_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(all_cheat[0:3])\n",
    "#v = mk_imgid(top_img)\n",
    "#print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc_in = zip(all_cheat, pred_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc_all = []\n",
    "for a,p in acc_in:\n",
    "    #print(a,p)\n",
    "    if len(a) == 0:\n",
    "        acc_i = 0\n",
    "    else:\n",
    "        acc_i = len(set(a).intersection(set(p)))/len(set(a))\n",
    "    acc_all.append(acc_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(pred_img)\n",
    "print(acc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(np.array(acc_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## all similarities\n",
    "all_sim_cv = []\n",
    "for l in range(len(all_i_txt)):\n",
    "    H = cv.fit_transform(all_i_txt[l])\n",
    "    sim = cosine_similarity(H)\n",
    "    all_sim_cv.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#similarities[-2] meaning taking only the array for question\n",
    "all_sim_q_cv = []\n",
    "for i in range(len(all_sim_cv)):\n",
    "    all_sim_q_cv.append(all_sim_cv[i][-2][:-2])\n",
    "print(len(all_sim_q_cv))\n",
    "#print(all_sim_q[971])\n",
    "#print(len(all_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cheat = mk_list(fe['curr_elim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cheat_code = zip(all_sim_q_cv, all_cheat)## Sort all the above similarities with argsort which gives indices\n",
    "## or we should not take top5 and make a threshold above which we will include it in the list of output?\n",
    "sorted_ind = []\n",
    "for si, ln in cheat_code:\n",
    "    y_top = si.argsort()[::-1][:len(ln)]\n",
    "    sorted_ind.append(y_top)\n",
    "#sorted_ind[971]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_img = zip(all_x, sorted_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert to img_id from index to match with actual image ids selcted by participant\n",
    "def mk_imgid(arr):\n",
    "    y_pred = []\n",
    "    for i,j in arr:\n",
    "        yp = []\n",
    "        for s in j:\n",
    "            yp.append(i[s])\n",
    "        y_pred.append(yp)\n",
    "    return y_pred\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_img = mk_imgid(top_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_in = zip(all_cheat, pred_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_all = []\n",
    "for a,p in acc_in:\n",
    "    #print(a,p)\n",
    "    if len(a) == 0:\n",
    "        acc_i = 0\n",
    "    else:\n",
    "        acc_i = len(set(a).intersection(set(p)))/len(set(a))\n",
    "    acc_all.append(acc_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(acc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(np.array(acc_all))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
