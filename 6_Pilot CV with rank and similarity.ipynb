{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.spatial.distance\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Import data\n",
    "qa = np.genfromtxt(\"uid_qa.txt\", delimiter = \",\", names = True, dtype = [('int64'), ('int64'), ('int64'), ('U256'), ('U128'),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fe = np.genfromtxt(\"uid_pre_elim.txt\", delimiter = \",\", names = True, dtype = [('int64'), ('int64'), ('int64'), ('U256'), ('U256'),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fe.dtype.names = ('uniqueID', 'bn', 'qn', 'pre_que', 'curr_elim')\n",
    "\n",
    "#fe.dtype.names\n",
    "#fe[971]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ftd = np.genfromtxt(\"face_id_descr.txt\", delimiter = \";\", skip_header = 1 , usecols = np.arange(0,2), dtype = [('U16'), ('U2056')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftd.dtype.names = ('img_id', 'description')\n",
    "len(ftd['img_id'])\n",
    "len(set(ftd['img_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Function- to convert sring into list.\n",
    "## First convert strings to list of rows equal to rows in fe by making a function\n",
    "## All image ids are one string in each row. By converting this string into list we will make each image ID an item in the list.\n",
    "\n",
    "def mk_list(str_vector):\n",
    "    des_byid = str_vector\n",
    "    all_x = []\n",
    "    for i in des_byid:\n",
    "        j = i.split()\n",
    "        #if len(j) > 0:\n",
    "        all_x.append(j)\n",
    "\n",
    "    return all_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "## convert strings in each row of pre-que to list of itmens.\n",
    "## each row of all_x contains a list of image id(S) before question is asked and action like elimination/selection is done.\n",
    "\n",
    "all_x = mk_list(fe['pre_que'])\n",
    "len(all_x)\n",
    "all_x[972]\n",
    "len(all_x[0])\n",
    "print(len(qa['que'][1473]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 43, 114, 115, 117, 118, 130, 131, 134, 135, 136, 137, 138, 139, 140, 234, 358, 408, 537, 607, 636, 674, 923, 928, 929, 931, 932, 949, 1078, 1079, 1196, 1250, 1251, 1258, 1264, 1274, 1364, 1433, 1493, 1494, 1545, 1600, 1753, 1907, 1996, 2045, 2077, 2095, 2103, 2105, 2106, 2167, 2168, 2169, 2201, 2308, 2312, 2413, 2455, 2535, 2536, 2542, 2657, 2681, 2706, 2772, 2773, 2774, 2778, 2779, 2781, 2782, 2783, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2798, 2873, 2876, 2902, 2942, 2949, 2965, 3079, 3201, 3207, 3258, 3308, 3411, 3416, 3426, 3439, 3440, 3444, 3445, 3446, 3449, 3496, 3506, 3507, 3549, 3600, 3602, 3610, 3612, 3616, 3619, 3621, 3624, 3626, 3628, 3652, 3654, 3655, 3656, 3665, 3682, 3715, 3726, 3727, 3730, 3733, 3735, 3829, 3912, 3954, 3959, 4001, 4002, 4003, 4004, 4005, 4006, 4007, 4008, 4024, 4025, 4302, 4335, 4363, 4415, 4450, 4522, 4523, 4536, 4572, 4621, 4723, 4734, 4736, 4737, 4792, 4793, 4794, 4823, 4824, 4825, 4826, 4827, 4828, 4829, 4830, 4898, 4904, 4916, 4989, 5019, 5040, 5061, 5062, 5065, 5120, 5133, 5354, 5439, 5511, 5526, 5527, 5528, 5529, 5530, 5585, 5676, 5679, 5681, 5688, 5709, 5712, 5713, 5714, 5715, 5717, 5718, 5720, 5723, 5725, 5734, 5754, 5782, 5918, 5977, 5997, 6104, 6106, 6113, 6117, 6320, 6346, 6513, 6575, 6595, 6626, 6627, 6628, 6629, 6633, 6783, 6909, 6939, 6955, 7096, 7144, 7187, 7413, 7472, 7484, 7497, 7662, 7714, 7715, 7777, 7860, 7865, 7871, 7873, 7875, 7880, 7885, 7890, 7891, 7893, 7894, 7895, 7897, 7900, 7902, 7905, 7930, 7999, 8040, 8067, 8108, 8223, 8233, 8234, 8239, 8324, 8400, 8401, 8410, 8493, 8576, 8589, 8756, 8780, 8850, 8852, 8894, 8899, 9005, 9151, 9295, 9528, 9530, 9535, 9601, 9635, 9681, 9696, 9697, 9878, 9879, 9976, 10132, 10140, 10224, 10228, 10231, 10245, 10261, 10354, 10357, 10358, 10359, 10457, 10467, 10479, 10481, 10489, 10506, 10515, 10540, 10600, 10635, 10636, 10637, 10638, 10639, 10643, 10707, 10708, 10728, 10729, 10788, 10812, 10890, 10975, 10976, 10977, 10987, 10993, 10995, 10996, 10998, 11001, 11003, 11025, 11104, 11117, 11195, 11196, 11228, 11231, 11243, 11244, 11245, 11392, 11418, 11430, 11461, 11463, 11509, 11553, 11600, 11661, 11672, 11683, 11688, 11696, 11698, 11708, 11709, 11716, 11720, 11910, 11924, 11936, 11954, 11955, 11965, 11967, 11972, 11975, 11982, 11985, 12104, 12133, 12174, 12203, 12231, 12232, 12240, 12241, 12242, 12243, 12337, 12428, 12432, 12437, 12519, 12525, 12593, 12690, 12730, 12731, 12778, 12779, 12788, 12797, 12798, 12842, 12875, 12878, 13011, 13017, 13037, 13054, 13058, 13059, 13063, 13071, 13072, 13083, 13084, 13093, 13094, 13162, 13189, 13191, 13217, 13221, 13245, 13351, 13402, 13405, 13518, 13558, 13564, 13645, 13680, 13684, 13690, 13692, 13790, 13797, 13799, 13800, 13894, 14009, 14010, 14011, 14012, 14013, 14016, 14143, 14167, 14189, 14190, 14191, 14192, 14193, 14194, 14195, 14197, 14198, 14199, 14200, 14201, 14202, 14204, 14205, 14206, 14207, 14208, 14209, 14210, 14211, 14212, 14251, 14266, 14326, 14364, 14416, 14617, 14670, 14672, 14673, 14677, 14870, 14893, 14916, 14932, 14953, 14954, 14955, 14957, 14959, 15071, 15098, 15124, 15125, 15127, 15128]\n"
     ]
    }
   ],
   "source": [
    "##check blanks\n",
    "## As there are some rows where there is only one image or blank/erronous question. We check that and save those indices.\n",
    "## create blank list\n",
    "#good_index = ['True']*len(all_x)\n",
    "\n",
    "bl =[]\n",
    "\n",
    "for img,q in zip(enumerate(all_x), mk_list(qa['que'])):\n",
    "    if (len(img[1]) <2 or len(q) < 2) and img[0] not in bl:\n",
    "        bl.append(img[0])\n",
    "print(bl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15131"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_x)\n",
    "len(mk_list(qa['que']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print bl\n",
    "#for n in bl[2000:400]:\n",
    "#    print(all_x[n], mk_list(qa['que'])[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Now for each row in the list above, find description and add it\n",
    "all_i_txt1 = []\n",
    "original_ind = []\n",
    "bl_ind = []\n",
    "\n",
    "for rown in range(len(all_x)):\n",
    "    if rown in bl:\n",
    "        bl_ind.append(rown)\n",
    "    else:\n",
    "        #print(all_x.index)\n",
    "        int_i_txt = []\n",
    "        for img in all_x[rown]:\n",
    "            if img in ftd['img_id']:\n",
    "                d = str(ftd['description'][list(ftd['img_id']).index(img)])\n",
    "                int_i_txt.append(str(d))\n",
    "        original_ind.append(rown)\n",
    "        all_i_txt1.append(int_i_txt)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14644\n",
      "14644\n",
      "487\n",
      "487\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#print check\n",
    "#print(type(all_i_txt[0]))\n",
    "#print(len(all_i_txt))\n",
    "#print(all_i_txt[971])\n",
    "#print(all_i_txt[1473])\n",
    "print(len(original_ind))\n",
    "print(len(all_i_txt1))\n",
    "print(len(bl_ind))\n",
    "print(len(bl))\n",
    "print(bl == bl_ind)\n",
    "#print(original_ind)\n",
    "#for it in original_ind:\n",
    "#    print(qa['ans'][it])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## add question and answer to each data point\n",
    "\n",
    "all_i_txt = [row + [qa['que'][rn].strip(), qa['ans'][rn].strip()] for rn, row in zip(original_ind, all_i_txt1)]\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An asian man in his early twenties.  He has a youthful face with some acne.  He has mid length black hair with shaved sides.  He has tanned skin.. 24 years. asian. Hispanic male[comma] mid twenties,short black hair, average build. 24 years. hispanic. A youngish man[comma] regular features, average looking. The hair parting is on the other side, gives a different look to the face, person seems to have some acne or skin problems. . 21 years. Asian. male. 20 years. asian. Mouth and ears look pretty normal.  Nose is a bit bulbous and red near the bottom.  Looks a bit angry because of the narrow eyes.  Bushy dark eyebrows.  Hair is longer on the top of the head than on the sides.. 28 years. african. . Chubby face and acne on face detected as well. Physically they appear to have broad shoulders with good posture.. 24 years. latino. . The person is average looking and simple.Small eyes with straight hair[comma]broad face.. 23 years. african. . Medium height[comma] Asian guy[comma] has acne and typical build with short hair. 21 years. african. . Short and a bit chubby. Hair cut is trendy[comma] but nothing too outrageous. Looks very serious.. 22 years. african. . short[comma] small build[comma] asian male[comma] brown hair[comma] brown eyes[comma] small eyes[comma] large lips. 26 years. african. . Slightly round face. Well-kept hair. About average height[comma] weight[comma] and build. Small amount of acne on their face.. 24 years. african. . He is kind of stalky.he looks upset.he is tall for an Asian guy. 26 years. african. . Short hair with a large come over. Shaved face[comma] and some pimples. Fair complexion[comma] and somewhat bushy eyebrows.  . 19 years. african. . This is a young man of uncertain ethnic descent. He may be either Asian or Hispanic[comma] and has dark hair and eyes. He is clean-shaven and has a moderate-length haircut.. 20 years. african. . This man is average hight[comma] has dark hair and eyes[comma] and looks like a mixture of white and Asian.. 20 years. african. . this person has parted hair and is cle',\n",
       " 'do he have a beard',\n",
       " 'No']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_i_txt[0])\n",
    "all_i_txt[0][15:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## check addition of above objects\n",
    "for i in range(len(all_i_txt)):\n",
    "    print(all_i_txt[i][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(all_i_txt[0])\n",
    "##basic model\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## all similarities\n",
    "all_sim = []\n",
    "for l in range(len(all_i_txt)):\n",
    "    H = cv.fit_transform(all_i_txt[l])\n",
    "    sim = cosine_similarity(H)\n",
    "    all_sim.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14644\n"
     ]
    }
   ],
   "source": [
    "#similarities[-2] meaning taking only the array for question\n",
    "all_sim_q = []\n",
    "for i in range(len(all_sim)):\n",
    "    all_sim_q.append(all_sim[i][-2][:-2])\n",
    "print(len(all_sim_q))\n",
    "#print(all_sim_q[971])\n",
    "#print(len(all_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Sort all the above similarities with argsort which gives indices\n",
    "## or we should not take top5 and make a threshold above which we will include it in the list of output?\n",
    "sorted_ind = []\n",
    "for si in all_sim_q:\n",
    "    y_top = si.argsort()[::-1]\n",
    "    sorted_ind.append(y_top)\n",
    "#sorted_ind[971]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## with above indices, create new sorted array per que, this is done to then find max step difference \n",
    "sorted_sim_all = []\n",
    "for q,w in zip(sorted_ind, all_sim_q):\n",
    "    sorted_sim = []\n",
    "    for e in q:\n",
    "        sorted_sim.append(w[e])\n",
    "    sorted_sim_all.append(sorted_sim)\n",
    "print(len(sorted_sim_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##find the difference between two similarity score in each array.\n",
    "sim_dif_all = []\n",
    "\n",
    "for d in range(len(sorted_sim_all)):\n",
    "    sim_dif = [sorted_sim_all[d][f-1] - sorted_sim_all[d][f] for f in range(1, len(sorted_sim_all[d]))]\n",
    "    sim_dif_all.append(sim_dif)\n",
    "        \n",
    "len(sim_dif_all)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(sim_dif_all)\n",
    "##this number is the index number of max difference and will can be used in sorted_sim_all to cut off, then use \n",
    "##[:this num+1]\n",
    "## the problem is that here for example if the image description is not there before the question or \n",
    "##images are not present\n",
    "## befor question, the description is empty. The similarity measure with question and answer is then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## The problem lies here...\n",
    "##question is why do I still have cases with one image id? Even though I am removing them earlier. What am I missing?\n",
    "\n",
    "max_dif = []\n",
    "max_dif_ind =[]\n",
    "for g in range(len(sim_dif_all)):\n",
    "    \n",
    "    maxi= max(sim_dif_all[g])\n",
    "    max_dif.append(maxi)\n",
    "    max_dif_ind.append(sim_dif_all[g].index(maxi))\n",
    "#print(len(max_dif))\n",
    "#print(len(max_dif_ind))\n",
    "#print(max_dif.index(None))\n",
    "#print(max_dif)\n",
    "#sim_dif_all[971]\n",
    "#sorted_sim_all[971]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(max_dif_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_ind_lim = [indi[0:max_indi+1] for indi,max_indi in zip(sorted_ind, max_dif_ind)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##clean_all_x\n",
    "all_x_clean = [all_x[i] for i in original_ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(all_x_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_img = zip(all_x_clean, sorted_ind_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top_img = zip(all_x, y_top_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert to img_id from index to match with actual image ids selcted by participant\n",
    "def mk_imgid(arr):\n",
    "    y_pred = []\n",
    "    for i,j in arr:\n",
    "        yp = []\n",
    "        for s in j:\n",
    "            yp.append(i[s])\n",
    "        y_pred.append(yp)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_img = mk_imgid(top_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pred_img)\n",
    "pred_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cheat1 = mk_list(fe['curr_elim'])\n",
    "all_cheat = [all_cheat1[i] for i in original_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(all_cheat)\n",
    "all_cheat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_all= [len(set(a).intersection(set(p)))/len(set(p)) if len(p) > 0 else 0 for a,p in zip(all_cheat, pred_img)]\n",
    "rec_all = [len(set(a).intersection(set(p)))/len(set(a)) if len(a) > 0 else 0 for a,p in zip(all_cheat, pred_img)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(pre_all))\n",
    "print(len(rec_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(0.5*0.5 + 1)*pre_all[0]*rec_all[0]/ (0.5*0.5*pre_all[0] + rec_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs_all= [(0.5*0.5 + 1)*pr*re/ (0.5*0.5*pr + re) if pr > 0 or re >0 else 0 for pr, re in zip(pre_all, rec_all)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_mean = np.mean(np.array(pre_all))\n",
    "rec_mean = np.mean(np.array(rec_all))\n",
    "fs_mean = np.mean(np.array(fs_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op1 = [\"1\", \"CV\", \"default\", \"Cosinesimilarity and ranking difference\",str(round(pre_mean,2)), str(round(rec_mean,2)), str(round(fs_mean,2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('Results with description.txt', 'w') as f:\n",
    "#    f.write(\"No.; Model; Parameter; Decision Rules; Precision; Recall; F0.5\"+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Results with description.txt', 'a') as f:\n",
    "    f.write('; '.join(op1) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
